<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Hexo</title>
  
  
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://yoursite.com/"/>
  <updated>2019-02-20T01:59:10.747Z</updated>
  <id>http://yoursite.com/</id>
  
  <author>
    <name>A Bad Candy</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>多种多样的卷积操作（下篇）</title>
    <link href="http://yoursite.com/2019/02/19/%E5%A4%9A%E7%A7%8D%E5%A4%9A%E6%A0%B7%E7%9A%84%E5%8D%B7%E7%A7%AF%E6%93%8D%E4%BD%9C%EF%BC%88%E4%B8%8B%E7%AF%87%EF%BC%89/"/>
    <id>http://yoursite.com/2019/02/19/多种多样的卷积操作（下篇）/</id>
    <published>2019-02-19T12:42:47.000Z</published>
    <updated>2019-02-20T01:59:10.747Z</updated>
    
    <summary type="html">
    
      &lt;h4 id=&quot;因果卷积&quot;&gt;&lt;a href=&quot;#因果卷积&quot; class=&quot;headerlink&quot; title=&quot;因果卷积&quot;&gt;&lt;/a&gt;因果卷积&lt;/h4&gt;&lt;p&gt;casual卷积最初随&lt;a href=&quot;https://arxiv.org/pdf/1609.03499.pdf&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;WaveNet&lt;/a&gt;一起提出,WaveNet是一个生成模型，类似于早期的pixel RNN和Pixel CNN，主要用来生成语音，声音元素是一个点一个点生成的。WaveNet是利用卷积来学习t时刻之前的输入数据（音频），来预测t+1时刻的输出. 对输入数据的顺序很注重, t时刻的输出仅仅依赖于1,2,…,t-1时刻的输入，不会依赖于t+1时刻以及之后时刻的输入。这与BiLSTM的思想截然不同。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;../../../../images/pasted-70.png&quot; alt=&quot;casual convolution&quot;&gt;&lt;/p&gt;
&lt;p&gt;由于声音文件是时间上的一维数组，16KHz的采样率的文件，每秒钟就会有16000个元素，而上面所说的因果卷积的感受野非常小，即使堆叠很多层也只能使用到很少的数据来生成t时刻的的元素，为了扩大卷积的感受野，WaveNet采用了堆叠了（stack）多层扩张（dilated ）卷积(&lt;a href=&quot;http://localhost:4000/2019/02/19/%E5%A4%9A%E7%A7%8D%E5%A4%9A%E6%A0%B7%E7%9A%84%E5%8D%B7%E7%A7%AF%E6%93%8D%E4%BD%9C%EF%BC%88%E4%B8%AD%E7%AF%87%EF%BC%89/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;中篇&lt;/a&gt;里有提到)来增大网络的感受野，使得网络生成下一个元素的时候，能够使用更多之前的元素数值。1D扩张卷积如下图所示：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;../../../../images/pasted-71.png&quot; alt=&quot;一维扩张卷积。在实现上，1D的dilate conv主要是通过padding来实现的。2D主要是通过mask filter map来实现的&quot;&gt;&lt;/p&gt;
&lt;p&gt;整个生成过程的动态图如下:&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;../../../../images/pasted-73.png&quot; alt=&quot;dilated casual convolution&quot;&gt;&lt;/p&gt;
&lt;h4 id=&quot;变形卷积&quot;&gt;&lt;a href=&quot;#变形卷积&quot; class=&quot;headerlink&quot; title=&quot;变形卷积&quot;&gt;&lt;/a&gt;变形卷积&lt;/h4&gt;&lt;p&gt;deformable卷积来自&lt;a href=&quot;https://arxiv.org/abs/1703.06211&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;论文《Deformable Convolutional Networks》&lt;/a&gt;,是MASA 2017年的作品，其灵感来源于Google DeepMind 2016年发表的&lt;a href=&quot;https://arxiv.org/abs/1506.02025&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;STN（Spatial Transform Network&lt;/a&gt;,但二者有着巨大的差别：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;STN作者说明了CNN对于输入数据缺乏空间变换不变性，因此引入了一个spatial transformer module，不需要额外的监督，能够以data-driven的方式学习得到输入图像或特征图的全局空间变换参数，赋予网络spatial invariant能力。ST模块可以分成三个部分：localization net根据输入的feature map回归spatial transform的参数θ，然后用这个参数去生成一个采样的grid，最后根据这个grid以及输入的feature map得到输出的经过空间变换的feature map。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&quot;../../../../images/pasted-79.png&quot; alt=&quot;STN&quot;&gt;&lt;/p&gt;
&lt;p&gt;具体而言，localization网络的输入是feature map U∈R^H×W×C，输出 θ=f_loc(U)，该层的结构通常是一个全连接网络或者卷积网络后接一个回归层来训练参数θ。 θ的size取决于我们预先定义的空间变换的类型（仿射，平移，缩放，旋转，剪切等），比如仿射变换的话，参数大小就是6维。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;../../../../images/pasted-83.png&quot; alt=&quot;parameterised sampling grid&quot;&gt;&lt;/p&gt;
&lt;p&gt;有了空间变换的参数之后，我们就可以知道输出的feature map上的每一个点在输入的feature map上的位置了。比如说对于二维的仿射变换，我们可以建立输出feature map上的坐标和输入feature map上坐标之间的映射关系：如公式：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;../../../../images/pasted-82.png&quot; alt=&quot;空间变换公式&quot;&gt;&lt;/p&gt;
&lt;p&gt;其中 (xti,yti)表示输出的feature map上的坐标，(xsi,ysi) 表示输出feature map上坐标对应在输入feature map上的采样点坐标。但此时往往(xsi,ysi)会落在原始输入特征图的几个像素点中间部分，所以需要利用双线性插值来计算出对应该点的灰度值。&lt;/p&gt;
&lt;p&gt;再来说说双线性插值，数字图像中实现缩放的方法有很多种，其中一种就是双线性插值，在实现图像缩放时，有两种方法来确定缩放后的图像的像素值，第一种是根据原图像中的的像素找到对应的缩放后的图像中的像素，第二种是根据缩放后的图像找到对应的原图像中的像素.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;../../../../images/pasted-85.png&quot; alt=&quot;projection&quot;&gt;&lt;/p&gt;
&lt;p&gt;但是第一种方法有缺点，因为小图中的像素点到大图中的像素点不是满射，因此大图中的点不能完全有像素值，第二种方法也有缺点，大图中的点逆映射为小图中的点时，得到的像素坐标值可能不是整数，一种办法是采用最近邻方法，即将得到的坐标值与相邻的原图像中的像素坐标值比较，取离得最近的坐标值对应的像素值作为缩放后的图像对应的坐标值的像素值，这种办法可能导致图像失真，因此采用双线性差值的办法来进行计算相应的像素值。&lt;/p&gt;
&lt;p&gt;在对图像进行仿射变换时，会出现一个问题，当原图像中某一点的坐标映射到变换后图像时，坐标可能会出现小数,如旋转后的右图所示，这样在原图中就没有对应的像素值。  &lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;../../../../images/pasted-88.png&quot; alt=&quot;旋转&quot;&gt;&lt;/p&gt;
&lt;p&gt;在实现时我们通常将变换后图像上所有的位置映射到原图像计算（这样做比正向计算方便得多），即依次遍历变换后图像上所有的像素点，根据仿射变换矩阵计算出映射到原图像上的坐标（可能出现小数），然后用双线性插值，根据该点周围4个位置的值加权平均得到该点值。过程可用如下图和公式表示：&lt;br&gt;&lt;img src=&quot;../../../../images/pasted-90.png&quot; alt=&quot;双线性插值&quot;&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;../../../../images/pasted-91.png&quot; alt=&quot;双线性插值公式&quot;&gt;&lt;br&gt;这里R1,Q11等均表示那一点的像素值。将R1,R2代入得：&lt;br&gt;&lt;img src=&quot;../../../../images/pasted-93.png&quot; alt=&quot;双线性插值公式&quot;&gt;&lt;/p&gt;
&lt;p&gt;知道了输出feature map在输入feature map上的采样点坐标之后，接下来就是要根据采样点的值确定输出目标点的值了。这里一般会用到kernel，以采样点为中心的kernel范围内的点对输出目标点的值都有贡献。&lt;br&gt;&lt;img src=&quot;../../../../images/pasted-97.png&quot; alt=&quot; &quot;&gt;&lt;br&gt;上式中，Vic是输出特征图的第c个通道中位置(xti,yti)处的像素i的值，所有的空间变换对于各个channel都是一样的。H′,W′表示输出的特征图的长宽。U表示输入特征图上第c个通道中点(m,n)的像素值，k表示预定义的kernel即采样核，xsi,ysi表示输入feature map上的采样点坐标，Φ表示kernel的参数。&lt;br&gt;可以这样理解：（1）输出特征图上某一点Vic的灰度值对应于输入特征图上某一点(xis,yis)的灰度值，而这点的灰度值由周围的若干点的灰度值Ucnm共同确定并且距离(xis,yis)越近（距离关系由xis-m和yis-n确定），影响越大（权重越大）。（2）具体的灰度插值方法由k()中Φx和Φy确定。当采用最近邻或双线性插值方法时，上述公式就退化成如下两个公式：&lt;br&gt;&lt;img src=&quot;../../../../images/pasted-101.png&quot; alt=&quot;最近邻插值&quot;&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;../../../../images/pasted-102.png&quot; alt=&quot;双线性插值&quot;&gt;&lt;/p&gt;
&lt;p&gt;双线性插值使得目标灰度值只与(xsi,ysi)周围4个点的灰度有关。具体来说，当|xsi−m|或者|ysi−n|大于1时，对应的max()项将取0，也就是说，只有(xsi,ysi)周围4个点的灰度值决定目标像素点的灰度并且当|xsi−m|和|ysi−n|越小，影响越大（即离点(xsi,ysi)越近，权重越大)，这和前面介绍双线性插值的结论是一致的。另外很重要的一点是，该公式对Ucnm和(xsi,ysi)是可导的，如下所示。也就是说，ST的变换过程是可以在网络中不断训练来修正参数的。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;../../../../images/pasted-104.png&quot; alt=&quot; &quot;&gt;&lt;/p&gt;
&lt;p&gt;U就是前一个CNN层的输出，包含参数w的，先对U求偏导才能继续对U中包含的前一层参数W求偏导。到localization的链式：z-&amp;gt;V-&amp;gt;theta。到前一层的链式：z-&amp;gt;V-&amp;gt;U-&amp;gt;W，localization等于在U后开了一个小门，误差一部分流到门就断了，把theta更新。另一部分还得从U往前流直到数据源输入层。最后根据以下公式求xis对θ的导数。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;../../../../images/pasted-106.png&quot; alt=&quot; &quot;&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;言归正传，在Deformable convolution一文中，以标准的3*3卷积为例：&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&quot;../../../../images/pasted-107.png&quot; alt=&quot;3*3卷积公式&quot;&gt;&lt;/p&gt;
&lt;p&gt;对于每个输出y(p0)，都要从x上采样9个位置，这9个位置都在中心位置x(p0)向四周扩散得到的gird形状上，(-1,-1)代表x(p0)的左上角，(1,1)代表x(p0)的右下角，其他类似。&lt;/p&gt;
&lt;p&gt;而在可变形卷积中，如下所言：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;../../../../images/pasted-109.png&quot; alt=&quot; &quot;&gt;&lt;/p&gt;
&lt;p&gt;同样对于每个输出y(p0)，都要从x上采样9个位置，这9个位置是中心位置x(p0)向四周扩散得到的，但是多了一个新的参数 ∆pn，允许采样点扩散成非gird形状.注意∆pn很有可能是小数，而feature map x上都是整数位置，这时候就需要双线性插值。最终deformable convolution如下图所示：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;../../../../images/pasted-111.png&quot; alt=&quot; convolution&quot;&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;原始图片或特征图（大小为b × h × w × c），记为U，经过一个普通卷积，卷积填充为same，即输出输入大小不变，对应的输出结果为（b × h × w × 2c)，记为V，输出的结果是指原图片U中每个像素的偏移量（x偏移与y偏移，因此为2c）。&lt;/li&gt;
&lt;li&gt;将U中图片的像素索引值与V相加，得到偏移后的position（即在原始图片U中的坐标值），需要将position值限定为图片大小以内。position的大小为（b × h × w × 2c)，但position只是一个坐标值，而且还是float类型的，我们需要这些float类型的坐标值获取像素值。&lt;/li&gt;
&lt;li&gt;取一个坐标值（a,b)，将其转换为四个整数，floor(a), ceil(a), floor(b), ceil(b)，将这四个整数进行整合，得到四对坐标（floor(a),floor(b)),  ((floor(a),ceil(b)),  ((ceil(a),floor(b)),  ((ceil(a),ceil(b))。这四对坐标每个坐标都对应U中的一个像素值，而我们需要得到(a,b)的像素值，这里采用双线性差值的方式计算（一方面得到的像素准确，另一方面可以进行反向传播）。&lt;/li&gt;
&lt;/ol&gt;
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>多种多样的卷积操作（中篇）</title>
    <link href="http://yoursite.com/2019/02/19/%E5%A4%9A%E7%A7%8D%E5%A4%9A%E6%A0%B7%E7%9A%84%E5%8D%B7%E7%A7%AF%E6%93%8D%E4%BD%9C%EF%BC%88%E4%B8%AD%E7%AF%87%EF%BC%89/"/>
    <id>http://yoursite.com/2019/02/19/多种多样的卷积操作（中篇）/</id>
    <published>2019-02-19T11:15:43.000Z</published>
    <updated>2019-02-20T01:59:02.929Z</updated>
    
    <summary type="html">
    
      &lt;h4 id=&quot;Transposed卷积（解卷积）&quot;&gt;&lt;a href=&quot;#Transposed卷积（解卷积）&quot; class=&quot;headerlink&quot; title=&quot;Transposed卷积（解卷积）&quot;&gt;&lt;/a&gt;Transposed卷积（解卷积）&lt;/h4&gt;&lt;p&gt;对于许多应用程序和在许多网络架构中，我们经常希望进行与正常卷积相反方向的转换，即我们希望执行上采样。一些示例包括生成高分辨率图像并将低维特征映射到高维空间，例如自动编码器或语义分割。（在后面的示例中，语义分割首先在编码器中提取要素图，然后在解码器中恢复原始图像大小，以便它可以对原始图像中的每个像素进行分类。）&lt;/p&gt;
&lt;p&gt;传统上，可以通过应用插值方案或手动创建规则来实现上采样。另一方面，诸如神经网络之类的现代架构倾向于让网络本身自动地学习正确的转换，而无需人为干预。为此，我们可以使用转置卷积。&lt;/p&gt;
&lt;p&gt;转置卷积在文献中也称为反卷积或分数跨步卷积。然而，值得注意的是，“反卷积”这个名称不太合适，因为转置卷积不是信号/图像处理中定义的真实反卷积。从技术上讲，信号处理中的反卷积会逆转卷积运算。这里情况不同。因此，一些作者强烈反对将转置卷积称为反卷积。人们称它为反卷积主要是因为简单。稍后，我们将看到为什么将这种操作称为转置卷积是自然而且更合适的。&lt;/p&gt;
&lt;p&gt;始终可以使用直接卷积实现转置卷积。对于下图中的示例，我们使用3 x 3内核在2 x 2输入上应用转置卷积，使用单位步幅填充2 x 2边框。上采样输出的大小为4 x 4。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;../../../../images/pasted-36.png&quot; alt=&quot;向上采样2 x 2输入到4 x 4输出&quot;&gt;&lt;/p&gt;
&lt;p&gt;有趣的是，通过应用花式填充和不同步幅，可以将相同的2 x 2输入图像映射到不同的图像大小。下面，转置卷积应用于相同的2 x 2输入（在输入之间插入1个0），使用单位步幅填充2 x 2边界的零。现在输出的大小为5 x 5。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;../../../../images/pasted-37.png&quot; alt=&quot;将2 x 2输入上采样到5 x 5输出&quot;&gt;&lt;/p&gt;
&lt;p&gt;在上面的例子中查看转置卷积可以帮助我们建立一些直觉。但是为了概括其应用，通过计算机中的矩阵乘法来研究它是如何实现的是有益的。从那里，我们也可以看到为什么“转置卷积”是一个合适的名称。&lt;/p&gt;
&lt;p&gt;在卷积中，让我们定义C作为我们的内核，Large作为输入图像，Small作为来自卷积的输出图像。在卷积（矩阵乘法）之后，我们将大图像下采样为小的输出图像。矩阵乘法中的卷积的实现遵循C x Large = Small。&lt;/p&gt;
&lt;p&gt;以下示例显示了此类操作的工作原理。它将输入Reshape为16 x 1矩阵，并将内核转换为稀疏矩阵（4 x 16）。然后在稀疏矩阵和有效输入之间应用矩阵乘法。之后，将得到的矩阵（4×1）转换回2×2输出。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;../../../../images/pasted-38.png&quot; alt=&quot;卷积的矩阵乘法：从大输入图像（4 x 4）到小输出图像（2 x 2）&quot;&gt;&lt;/p&gt;
&lt;p&gt;现在，如果我们在方程的两边多重矩阵CT的转置，并使用矩阵与其转置矩阵的乘法给出单位矩阵的属性，那么我们有以下公式CT x Small = Large，如下所示下面的图片：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;../../../../images/pasted-39.png&quot; alt=&quot;卷积的矩阵乘法：从小输入图像（2 x 2）到大输出图像（4 x 4）&quot;&gt;&lt;/p&gt;
&lt;p&gt;正如您在此处所看到的，我们执行从小图像到大图像的上采样。这就是我们想要实现的目标。现在，您还可以看到“转置卷积”这个名称的来源。&lt;/p&gt;
&lt;h5 id=&quot;棋盘效应&quot;&gt;&lt;a href=&quot;#棋盘效应&quot; class=&quot;headerlink&quot; title=&quot;棋盘效应&quot;&gt;&lt;/a&gt;棋盘效应&lt;/h5&gt;&lt;p&gt;人们在使用转置卷积时观察到的一种令人不快的行为是所谓的棋盘格伪影。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;../../../../images/pasted-40.png&quot; alt=&quot;A few examples of checkerboard artifacts&quot;&gt;&lt;/p&gt;
&lt;p&gt;该&lt;a href=&quot;https://distill.pub/2016/deconv-checkerboard&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;论文《Deconvolution and Checkerboard Artifacts》&lt;/a&gt;大约有此行为的精彩描述。有关更多详细信息，请查看此文章。在这里，我只概括几个要点。&lt;/p&gt;
&lt;p&gt;棋盘伪影是由转置卷积的“不均匀重叠”引起的。这种重叠使得更多的隐喻性绘画在某些地方比其他地方更多。&lt;/p&gt;
&lt;p&gt;在下图中，顶部的图层是输入图层，底部的图层是转置卷积后的输出图层。在转置卷积期间，具有较小尺寸的层被映射到具有较大尺寸的层。&lt;/p&gt;
&lt;p&gt;在示例（a）中，步幅为1且filer大小为2.如红色所示，输入上的第一个像素映射到输出上的第一个和第二个像素。如绿色所示，输入上的第二个像素映射到输出上的第二个和第三个像素。输出上的第二个像素从输入上的第一个和第二个像素接收信息。总的来说，输出中间部分的像素从输入端接收相同数量的信息。这里存在核心重叠的区域。由于在示例（b）中过滤器尺寸增加到3，所以接收最多信息的中心部分收缩。但这可能不是什么大问题，因为重叠仍然是均匀的。输出中心部分的像素从输入接收相同数量的信息。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;../../../../images/pasted-41.png&quot; alt=&quot; &quot;&gt;&lt;/p&gt;
&lt;p&gt;现在，对于下面的示例，我们更改stride = 2.在示例（a）中，filter size = 2，输出上的所有像素都从输入接收相同数量的信息。它们都从输入上的单个像素接收信息。这里没有转置卷积的重叠。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;../../../../images/pasted-42.png&quot; alt=&quot; &quot;&gt;&lt;/p&gt;
&lt;p&gt;如果我们在示例（b）中将filter大小更改为4，则均匀重叠的区域会缩小。但是，仍然可以使用输出的中心部分作为有效输出，其中每个像素从输入接收相同数量的信息。&lt;/p&gt;
&lt;p&gt;然而，如果我们在示例（c）和（d）中将filter大小更改为3和5，则事情变得有趣。对于这两种情况，输出上的每个像素与其相邻像素相比接收不同量的信息。人们无法在输出上找到连续且均匀重叠的区域。&lt;/p&gt;
&lt;p&gt;当过滤器大小不能被步幅整除时，转置的卷积具有不均匀的重叠。这种“不均匀的重叠”使得更多的油漆在某些地方比其他地方更多，从而产生了棋盘效果。事实上，不均匀重叠的区域在两个维度上往往更加极端。在那里，两个模式相乘，不均匀性得到平方。&lt;/p&gt;
&lt;p&gt;在应用转置卷积时，可以做两件事来减少这种伪影。首先，确保使用按步幅划分的filer大小，避免重叠问题。其次，可以使用stride = 1的转置卷积，这有助于减少棋盘格效果。然而，正如许多最近的模型中所见，工件仍然可以泄漏。&lt;/p&gt;
&lt;p&gt;所述&lt;a href=&quot;https://distill.pub/2016/deconv-checkerboard/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;论文&lt;/a&gt;进一步提出了更好的上采样的方法：首先调整图像的大小（使用最近邻插值或双线性插值），然后执行一个卷积层。通过这样做，作者避免了棋盘格效应。您可能想要为您的应用程序尝试它。&lt;/p&gt;
&lt;h4 id=&quot;扩张卷积（Atrous-Convolution）&quot;&gt;&lt;a href=&quot;#扩张卷积（Atrous-Convolution）&quot; class=&quot;headerlink&quot; title=&quot;扩张卷积（Atrous Convolution）&quot;&gt;&lt;/a&gt;扩张卷积（Atrous Convolution）&lt;/h4&gt;&lt;p&gt;扩张卷积在&lt;a href=&quot;https://arxiv.org/abs/1412.7062&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;论文&lt;/a&gt;和&lt;a href=&quot;https://arxiv.org/abs/1511.07122&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;论文《Multi-scale context aggregation by dilated convolutions》&lt;/a&gt;中引入。&lt;/p&gt;
&lt;p&gt;这是标准的离散卷积：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;../../../../images/pasted-43.png&quot; alt=&quot;离散卷积公式&quot;&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;../../../../images/pasted-44.png&quot; alt=&quot;标准离散卷积&quot;&gt;&lt;/p&gt;
&lt;p&gt;扩张的卷积如下：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;../../../../images/pasted-45.png&quot; alt=&quot;扩张卷积公式&quot;&gt;&lt;/p&gt;
&lt;p&gt;当l = 1时，扩张卷积变为标准卷积。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;../../../../images/pasted-46.png&quot; alt=&quot;扩张卷积&quot;&gt;&lt;/p&gt;
&lt;p&gt;直观地说，扩张的卷积通过在内核元素之间插入空格来“扩展”内核。这个附加参数l（扩张率）表示我们想要扩展内核的程度。实现可能会有所不同，但内核元素之间通常会插入l-1个空格。下图显示了l = 1,2和4时的内核大小。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;../../../../images/pasted-47.png&quot; alt=&quot;扩张卷积的接收域。我们基本上可以得到一个大的感受野而不增加额外的成本&quot;&gt;&lt;/p&gt;
&lt;p&gt;在图像中，3×3个红点表示在卷积之后，输出图像具有3×3像素。尽管所有三个扩张的卷积都为输出提供了相同的尺寸，但模型观察到的感受野却非常不同。接受率为3 x 3，l = 1。l = 2时为7 x 7。对于l = 3，感受野增加到15 x 15.有趣的是，与这些操作相关的参数数量基本相同。我们“观察”一个大的感受野而不增加额外的成本。因此，扩张卷积用于廉价地增加输出单元的感受野而不增加核尺寸，这在多个扩张的卷积一个接一个地堆叠时尤其有效。&lt;/p&gt;
&lt;p&gt;文章“Multi-scale context aggregation by dilated convolutions”的作者在多层扩张卷积中构建了一个网络，其中扩张率l在每一层呈指数增长。结果，有效的感受野呈指数增长，而参数的数量只随着层线性增长！本文中的扩张卷积用于系统地聚合多尺度上下文信息而不会丢失分辨率。本文表明，所提出的模块提高了当时最先进的语义分割系统的准确性（2016）。请查看论文以获取更多信息。&lt;/p&gt;
&lt;h4 id=&quot;分离卷积&quot;&gt;&lt;a href=&quot;#分离卷积&quot; class=&quot;headerlink&quot; title=&quot;分离卷积&quot;&gt;&lt;/a&gt;分离卷积&lt;/h4&gt;&lt;p&gt;可分离的卷积用于一些神经网络体系结构，例如&lt;a href=&quot;https://arxiv.org/abs/1704.04861&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;MobileNet&lt;/a&gt;。可以在空间上（空间可分离卷积）或深度（深度可分离卷积）上执行可分离卷积。&lt;/p&gt;
&lt;h5 id=&quot;空间可分离的卷积&quot;&gt;&lt;a href=&quot;#空间可分离的卷积&quot; class=&quot;headerlink&quot; title=&quot;空间可分离的卷积&quot;&gt;&lt;/a&gt;空间可分离的卷积&lt;/h5&gt;&lt;p&gt;空间可分离卷积在图像的2D空间维度上操作，即高度和宽度。从概念上讲，空间可分离卷积将卷积分解为两个单独的操作。对于下面显示的示例，Sobel内核（3x3内核）被划分为3x1和1x3内核。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;../../../../images/pasted-48.png&quot; alt=&quot;Sobel内核可以被划分为3×1和1×3的内核&quot;&gt;&lt;/p&gt;
&lt;p&gt;在卷积中，3x3内核直接与图像卷积。在空间可分离的卷积中，3x1内核首先与图像卷积。然后应用1x3内核。在执行相同操作时，这将需要6个而不是9个参数。&lt;/p&gt;
&lt;p&gt;此外，在空间上可分离的卷积中需要比标准卷积更少的矩阵乘法。对于一个具体的例子，在具有3×3内核（stride = 1，padding = 0）的5×5图像上的卷积需要在水平3个位置（和垂直3个位置）扫描内核。总共9个位置，如下图所示。在每个位置，应用9个元素乘法。总的来说，这是9 x 9 = 81次乘法。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;../../../../images/pasted-49.png&quot; alt=&quot;单通道标准卷积&quot;&gt;&lt;/p&gt;
&lt;p&gt;另一方面，对于空间可分离的卷积，我们首先在5 x 5图像上应用3 x 1 filter。我们在水平5个位置和垂直3个位置扫描这样的内核。总共5 x 3 = 15个位置，如下图所示。在每个位置，应用3个元素乘法。那是15 x 3 = 45次乘法。我们现在获得了3 x 5矩阵。此矩阵现在与1 x 3内核进行卷积，内核在水平3个位置和垂直3个位置扫描矩阵。对于这9个位置中的每一个，应用3个元素乘法。此步骤需要9 x 3 = 27次乘法。因此，总体而言，空间可分离卷积需要45 + 27 = 72次乘法，这小于标准卷积所需次数。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;../../../../images/pasted-50.png&quot; alt=&quot;具有1个通道的空间可分离卷积&quot;&gt;&lt;/p&gt;
&lt;p&gt;让我们稍微扩展一下上面的例子。假设我们现在在带有m x m大小内核的N x N图像上应用卷积，其中stride = 1且padding = 0。传统的卷积需要（N-2）x（N-2）x m x m乘法。空间可分离卷积需要N x（N-2）x m +（N-2）×（N-2）× m =（2N-2）×（N-2）× m 次乘法。空间可分卷积与标准卷积之间的计算成本比率为：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;../../../../images/pasted-51.png&quot; alt=&quot; &quot;&gt;&lt;/p&gt;
&lt;p&gt;对于图像尺寸N远大于filter尺寸m（N &amp;gt;&amp;gt; m）的层，该比率变为2 / m。这意味着在这种渐近情况下（N &amp;gt;&amp;gt; m），空间可分卷积的计算成本是3 x 3 filter的标准卷积的2/3。5 x 5 filter为2/5，7 x 7 filter为2/7，依此类推。&lt;/p&gt;
&lt;p&gt;虽然空间可分离的卷积可以节省成本，但很少用于深度学习。其中一个主要原因是并非所有内核都可以分为两个较小的内核。如果我们通过空间可分的卷积替换所有传统的卷积，我们限制自己在训练期间搜索所有可能的核。训练结果可能不是最佳的。&lt;/p&gt;
&lt;h5 id=&quot;深度可分离的卷积&quot;&gt;&lt;a href=&quot;#深度可分离的卷积&quot; class=&quot;headerlink&quot; title=&quot;深度可分离的卷积&quot;&gt;&lt;/a&gt;深度可分离的卷积&lt;/h5&gt;&lt;p&gt;现在，让我们转到深度可分离卷积，这在深度学习中更常用（例如在&lt;a href=&quot;https://arxiv.org/abs/1704.04861&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;MobileNet&lt;/a&gt;和&lt;a href=&quot;https://arxiv.org/abs/1610.02357&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Xception&lt;/a&gt;中）。深度可分离的旋转包括两个步骤：深度卷积和1x1卷积。&lt;/p&gt;
&lt;p&gt;在描述这些步骤之前，值得重新审视我之前部分中讨论的2D卷积和1 x 1卷积。让我们快速回顾一下标准2D卷积。举一个具体的例子，假设输入层的大小为7 x 7 x 3（高x宽x通道），并且过滤器大小为3 x 3 x 3.在使用一个过滤器进行2D卷积后，输出层为尺寸为5 x 5 x 1（仅有1个通道）。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;../../../../images/pasted-52.png&quot; alt=&quot;标准2D二维卷积，使用1个filter创建1层输出&quot;&gt;&lt;/p&gt;
&lt;p&gt;通常，在两个神经网络层之间应用多个过滤器。假设我们这里有128个过滤器。在应用这128个2D卷积后，我们有128个5 x 5 x 1输出映射。然后我们将这些地图堆叠成一个大小为5 x 5 x 128的单层。通过这样做，我们将输入层（7 x 7 x 3）转换为输出层（5 x 5 x 128）。空间尺寸，即高度和宽度，缩小，而深度延长。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;../../../../images/pasted-53.png&quot; alt=&quot;标准2D卷积，使用128个filter创建128层输出&quot;&gt;&lt;/p&gt;
&lt;p&gt;现在有了深度可分离的卷积，让我们看看我们如何实现相同的转换。&lt;/p&gt;
&lt;p&gt;首先，我们将深度卷积应用于输入层。我们不是在2D卷积中使用尺寸为3 x 3 x 3的单个过滤器，而是分别使用3个内核。每个lter的大小为3 x 3 x 1.每个内核与输入层的1个通道进行卷积（仅1个通道，而不是所有通道！）。每个这样的卷积提供尺寸为5×5×1的图。然后我们将这些图堆叠在一起以创建5×5×3图像。在此之后，我们的输出尺寸为5 x 5 x 3.我们现在缩小空间尺寸，但深度仍然与以前相同。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;../../../../images/pasted-54.png&quot; alt=&quot;深度可分离卷积 - 第一步：我们使用3个内核，而不是在2D卷积中使用大小为3 x 3 x 3的单个过滤器。每个filter的大小为3 x 3 x 1.每个内核与输入层的1个通道进行卷积（仅1个通道，而不是所有通道！）。每个这样的卷积提供尺寸为5×5×1的图。然后我们将这些图堆叠在一起以创建5×5×3图像。在此之后，我们的输出尺寸为5 x 5 x 3。&quot;&gt;&lt;/p&gt;
&lt;p&gt;作为深度可分离卷积的第二步，为了扩展深度，我们应用1x1卷积，内核大小为1x1x3。将5 x 5 x 3输入图像与每个1 x 1 x 3内核进行对比，得到5x5x1大小的特征图。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;../../../../images/pasted-55.png&quot; alt=&quot; &quot;&gt;&lt;/p&gt;
&lt;p&gt;因此，在应用128个1x1卷积后，我们可以得到一个尺寸为5 x 5 x 128的层。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;../../../../images/pasted-56.png&quot; alt=&quot;深度可分卷积 - 第二步：应用多个1 x 1卷积来改变深度&quot;&gt;&lt;/p&gt;
&lt;p&gt;通过这两个步骤，深度可分离卷积还将输入层（7 x 7 x 3）转换为输出层（5 x 5 x 128）。&lt;/p&gt;
&lt;p&gt;深度可分离卷积的整个过程如图所示&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;../../../../images/pasted-57.png&quot; alt=&quot;The overall process of depthwise separable convolution.&quot;&gt;&lt;/p&gt;
&lt;p&gt;那么，深度可分离卷积的优势是什么？高效！与2D卷积相比，对于深度可分离卷积，需要更少的操作。&lt;/p&gt;
&lt;p&gt;让我们回顾一下2D卷积示例的计算成本。有128个3x3x3内核移动5x5次。这是128 x 3 x 3 x 3 x 5 x 5 = 86,400次乘法。&lt;/p&gt;
&lt;p&gt;可分离的卷积怎么样？在第一个深度卷积步骤中，有3个3x3x1内核移动5x5次。那是3x3x3x1x5x5 = 675次乘法。在1 x 1卷积的第二步中，有128个1x1x3内核移动5x5次。这是128 x 1 x 1 x 3 x 5 x 5 = 9,600次乘法。因此，总体而言，深度可分离卷积需要675 + 9600 = 10,275次乘法。这只是2D卷积成本的12％左右！&lt;/p&gt;
&lt;p&gt;因此，对于具有任意大小的图像，如果我们应用深度可分离卷积，我们可以节省多少时间。让我们稍微概括一下上面的例子。现在，对于大小为H x W x D的输入图像，我们想要使用大小为h x h x D的Nc内核进行2D卷积（stride = 1，padding = 0），其中h是偶数。这将输入层（H x W x D）变换为输出层（H-h + 1×W-h + 1×Nc）。所需的总体乘法是&lt;/p&gt;
&lt;p&gt;Nc x h x h x D x（H-h + 1）x（W-h + 1）&lt;/p&gt;
&lt;p&gt;另一方面，对于相同的变换，深度可分离卷积所需的乘法是&lt;/p&gt;
&lt;p&gt;D x h x h x 1 x（H-h + 1）x（W-h + 1）+ Nc x 1 x 1 x D x（H-h + 1）x（W h + 1）=（h x h + Nc）x D x（H-h + 1）x（W-h + 1）&lt;/p&gt;
&lt;p&gt;深度可分卷积与2D卷积之间的乘法比率现在为：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;../../../../images/pasted-58.png&quot; alt=&quot; &quot;&gt;&lt;/p&gt;
&lt;p&gt;对于大多数现代架构，输出层通常具有许多通道，例如数百甚至数千。对于这样的层（Nc &amp;gt;&amp;gt; h），则上述表达式降低至1 / h / h。这意味着对于这种渐近表达，如果使用3 x 3 filters，则2D卷积的乘法比深度可分离卷积多9倍。对于5 x 5 filters，2D卷积的乘法次数增加了25倍。&lt;/p&gt;
&lt;p&gt;使用深度可分离卷积有任何缺点吗？当然有。深度可分离卷积减少了卷积中的参数数量。因此，对于小型模型，如果2D卷积被深度可分离卷积替换，则模型容量可以显着降低。结果，该模型可能变得次优。但是，如果使用得当，深度可分离卷积可以为您提供效率，而不会显着损害您的模型性能。&lt;/p&gt;
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>多种多样的卷积操作（上篇）</title>
    <link href="http://yoursite.com/2019/02/19/%E5%A4%9A%E7%A7%8D%E5%A4%9A%E6%A0%B7%E7%9A%84%E5%8D%B7%E7%A7%AF%E6%93%8D%E4%BD%9C%EF%BC%88%E4%B8%8A%E7%AF%87%EF%BC%89/"/>
    <id>http://yoursite.com/2019/02/19/多种多样的卷积操作（上篇）/</id>
    <published>2019-02-19T09:10:00.000Z</published>
    <updated>2019-02-20T01:58:35.338Z</updated>
    
    <summary type="html">
    
      &lt;h4 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h4&gt;&lt;p&gt;不知不觉又快到了找工作的季节，慕然回想一下自己这两年学过的知识，大部分都变得陌生却又有点熟悉。于是乎决定重拾自己之前在&lt;a href=&quot;https://blog.csdn.net/qq_26293147?t=1&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;CSDN&lt;/a&gt;上写博客的热情，但是发现CSDN的界面又chou了许多… 所以还是花费了点时间自己搭Github Page + Hexo，准备把最近自己复习整理的知识点一一记录下来，与大家一起交流学习！ 话不多说，今天第一篇博客主要分享下卷积神经网络CNN中各种花式卷积操作，结合自己之前看过的论文和资料以及最近微博上爱可可老师分享的文章&lt;a href=&quot;https://medium.com/m/global-identity?redirectUrl=https%3A%2F%2Ftowardsdatascience.com%2Fa-comprehensive-introduction-to-different-types-of-convolutions-in-deep-learning-669281e58215&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;《A Comprehensive Introduction to Different Types of Convolutions in Deep Learning》&lt;/a&gt;,来一起感受下深度学习中“卷积”的魅力~ （注：本文主要翻译该篇文章，并加上自己的理解，同时会扩展提到其他几种不同的卷积形式）&lt;/p&gt;
&lt;p&gt;本文内容较多，故分为上中下三篇，上篇包括：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;卷积与互相关&lt;/li&gt;
&lt;li&gt;深度学习中的卷积（单通道版本，多通道版本）&lt;/li&gt;
&lt;li&gt;3D卷积&lt;/li&gt;
&lt;li&gt;1 x 1卷积&lt;/li&gt;
&lt;li&gt;卷积数学基础&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;中篇包括：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;转置(Transposed)卷积（反卷积Deconvolution，棋盘伪影）&lt;/li&gt;
&lt;li&gt;扩张(Dilated)卷积（Atrous Convolution）&lt;/li&gt;
&lt;li&gt;可分离(Seperable)卷积（空间可分离卷积，深度分离卷积）&lt;/li&gt;
&lt;li&gt;扁平(Flatten)卷积&lt;/li&gt;
&lt;li&gt;分组(Group)卷积&lt;/li&gt;
&lt;li&gt;打乱(Shuffle)分组卷积&lt;/li&gt;
&lt;li&gt;逐点(Point-wise)分组卷积  &lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;下篇为本人补充，包括：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;因果(Casual)卷积  &lt;/li&gt;
&lt;li&gt;变形(Deformable)卷积&lt;/li&gt;
&lt;li&gt;上采样（Unpooling）&lt;/li&gt;
&lt;li&gt;Graph Convolution&lt;/li&gt;
&lt;li&gt;Spherical CNNs&lt;/li&gt;
&lt;li&gt;深度学习框架中的卷积实现&lt;/li&gt;
&lt;/ol&gt;
&lt;h4 id=&quot;卷积与互相关&quot;&gt;&lt;a href=&quot;#卷积与互相关&quot; class=&quot;headerlink&quot; title=&quot;卷积与互相关&quot;&gt;&lt;/a&gt;卷积与互相关&lt;/h4&gt;&lt;p&gt;卷积是信号处理，图像处理和其他工程/科学领域中广泛使用的技术。在深度学习中，一种模型架构，即卷积神经网络（CNN），以此技术命名。然而，深度学习中的卷积本质上是信号/图像处理中的互相关。这两个算子之间存在微妙的差异。&lt;/p&gt;
&lt;p&gt;在信号/图像处理中，卷积定义为：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;../../../../images/pasted-4.png&quot; alt=&quot;卷积公式&quot;&gt;&lt;/p&gt;
&lt;p&gt;它被定义为两个函数在反转和移位后的乘积的积分。以下可视化展示了这一想法。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;../../../../images/pasted-5.png&quot; alt=&quot;信号处理中的卷积&quot;&gt;&lt;br&gt;滤波器g反转，然后沿水平轴滑动。对于每个位置，我们计算f和反向g之间的交点面积。交叉区域是该特定位置的卷积值。 从该&lt;a href=&quot;http://fourier.eng.hmc.edu/e161/lectures/convolution/index.html&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;链接&lt;/a&gt;采用并编辑图像。&lt;/p&gt;
&lt;p&gt;这里，函数g是滤波器(filter)。它反转，然后沿水平轴滑动。对于每个位置，我们计算f和反向g之间的交点面积。该交叉区域是该特定位置的卷积值。&lt;/p&gt;
&lt;p&gt;另一方面，互相关被称为滑动点积或两个函数的滑动内积。互相关的滤波器不会反转。它直接滑过函数f。f和g之间的交叉区域是互相关。下图显示了卷积和互相关之间的差异。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;../../../../images/pasted-6.png&quot; alt=&quot;信号处理中卷积和互相关之间的差异&quot;&gt;&lt;br&gt;图像由&lt;a href=&quot;https://en.wikipedia.org/wiki/Convolution&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;维基百科采用和编辑&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;在深度学习中，卷积中的滤波器不会被逆转。严格来说，它是互相关操作。我们基本上执行逐元素乘法和加法。但是，在深度学习中将其称为卷积是一种惯例。这是可以的，因为在训练期间过滤器的权值是学习得到的。如果上述示例中的反转函数g是正确的函数，则在训练之后，学习的过滤器看起来就像反转函数g。因此，在训练之前不需要像真正的卷积那样反转滤波器。(补充：而数字图像处理中经常提到的一些边缘检测算子，如Canny算子，Sobel算子和Laplace算子等等，这些滤波器模板的参数是固定的，或者说是由近似一阶差分提出系数后得到的，再跟原图f(x)做卷积运算就可以检测边缘了，如下图所示为一些常用滤波器模板)&lt;br&gt;&lt;img src=&quot;../../../../images/pasted-7.png&quot; alt=&quot;滤波器模板&quot;&gt;&lt;/p&gt;
&lt;h4 id=&quot;深度学习中的卷积&quot;&gt;&lt;a href=&quot;#深度学习中的卷积&quot; class=&quot;headerlink&quot; title=&quot;深度学习中的卷积&quot;&gt;&lt;/a&gt;深度学习中的卷积&lt;/h4&gt;&lt;p&gt;进行卷积的目的是从输入中提取有用的特征。在图像处理中，可以选择用于卷积的各种不同的滤波器。每种类型的滤波器都有助于从输入图像中提取不同的方面或特征，例如水平/垂直/对角线边缘。同样，在卷积神经网络中，使用滤波器通过卷积操作提取原始图像中不同的特征，而滤波器的权重在训练期间是自动学习的。然后将所有这些提取的特征“组合”以做出决策。&lt;/p&gt;
&lt;p&gt;进行卷积有一些优点，例如权重共享和平移不变性。卷积还将像素的空间关系考虑在内。这些可能非常有用，特别是在许多计算机视觉任务中，因为这些任务通常涉及识别某些组件与其他组件具有某些空间关系的对象（例如，狗的身体通常链接到头部，四条腿和尾部）。&lt;/p&gt;
&lt;h5 id=&quot;卷积：单通道版本&quot;&gt;&lt;a href=&quot;#卷积：单通道版本&quot; class=&quot;headerlink&quot; title=&quot;卷积：单通道版本&quot;&gt;&lt;/a&gt;卷积：单通道版本&lt;/h5&gt;&lt;p&gt;&lt;img src=&quot;../../../../images/pasted-8.png&quot; alt=&quot;单通道版本卷积&quot;&gt;&lt;br&gt;图片来源于&lt;a href=&quot;https://medium.com/m/global-identity?redirectUrl=https%3A%2F%2Ftowardsdatascience.com%2Fintuitively-understanding-convolutions-for-deep-learning-1f6f42faee1&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;这里&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;在深度学习中，卷积是元素乘法和加法。对于具有1个通道的图像，将在下面的图中演示卷积。这里的滤波器是一个3 x 3矩阵，元素[[0,1,2]，[2,2,0]，[0,1,2]]。滤波器在输入端滑动。在每个位置，它都在进行元素乘法和加法。每个滑动位置最终都有一个数字。然后，最终输出是3×3矩阵。（注意，在这个例子中，stride = 1和padding = 0。这些概念将在下面的数学基础部分中描述。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;../../../../images/pasted-10.png&quot; alt=&quot;cs231n课程中的单通道卷积示意图&quot;&gt;&lt;/p&gt;
&lt;h5 id=&quot;卷积：多通道版本&quot;&gt;&lt;a href=&quot;#卷积：多通道版本&quot; class=&quot;headerlink&quot; title=&quot;卷积：多通道版本&quot;&gt;&lt;/a&gt;卷积：多通道版本&lt;/h5&gt;&lt;p&gt;在许多应用程序中，我们处理的是具有多个通道的图像。典型的例子是RGB图像。每个RGB通道都强调原始图像的不同方面，如下图所示。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;../../../../images/pasted-9.png&quot; alt=&quot;不同通道强调原始图像的不同方面&quot;&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;../../../../images/pasted-11.png&quot; alt=&quot;cs231n课程中的多通道卷积示意图&quot;&gt;&lt;/p&gt;
&lt;p&gt;多通道数据的另一个例子是卷积神经网络中的层。卷积网络层通常由多个通道（通常为数百个通道）组成。每个通道都描述了前一层的不同方面。我们如何在具有不同深度的层之间进行过渡？我们如何将深度为n的图层转换为深度为m的后续图层？&lt;/p&gt;
&lt;p&gt;在描述该过程之前，我们想澄清一些术语：层(layers)，通道(channels)，特征图(feature maps)，过滤器(filters)和内核(kernels)。从层次结构的角度来看，层和过滤器的概念处于同一级别，而通道和内核位于下一级。通道和特征图是一回事。图层可以有多个通道（或特征图）：如果输入是RGB图像，则输入图层有3个通道。“通道”通常用于描述“层”的结构。类似地，“内核”用于描述“过滤器”的结构。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;../../../../images/pasted-14.png&quot; alt=&quot;Difference between “layer” (“filter”) and “channel” (“kernel”).&quot;&gt;&lt;/p&gt;
&lt;p&gt;filter和kernel之间的差异有点棘手。有时，它们可以互换使用，这可能会产生混淆。从本质上讲，这两个术语具有微妙的差异。“kernel”指的是2D权重阵列。术语“filter”用于堆叠在一起的多个kernel的3D结构。对于2D filter，filter与kernel相同。但对于3D filter和深度学习中的大多数卷积，filter是kernel的集合。每个kernel都是独一无二的，强调输入通道的不同方面。&lt;/p&gt;
&lt;p&gt;有了这些概念，多通道卷积如下。将每个kernel应用到前一层的输入通道上以生成一个输出通道。这是一个kernel-wise的过程。我们为所有kernel重复这样的过程以生成多个通道。然后将这些通道中的每一个加在一起以形成单个输出通道。下图应该使该过程更清晰。&lt;/p&gt;
&lt;p&gt;这里输入层是一个5 x 5 x 3矩阵，有3个通道。filter是3 x 3 x 3矩阵。首先，将filter中的每个kernel分别应用于输入层中的三个通道。执行三次卷积，产生3个尺寸为3×3的通道。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;../../../../images/pasted-15.png&quot; alt=&quot;用于多通道2D卷积的第一步：滤波器中的每个kernel分别应用于输入层中的三个通道&quot;&gt;&lt;br&gt;然后将这三个通道相加（元素加法）以形成一个单通道（3 x 3 x 1）。该通道是使用滤波器（3×3×3矩阵）对输入层（5×5×3矩阵）进行卷积的结果。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;../../../../images/pasted-16.png&quot; alt=&quot;用于多通道的2D卷积的第二步：然后将这三个通道相加在一起（逐元素加法）以形成一个单通道&quot;&gt;&lt;/p&gt;
&lt;p&gt;同样，我们可以将此过程视为通过输入层滑动3D滤波器矩阵。请注意，输入层和filter具有相同的深度（channel数=kernel数）。3D filter仅在图像的2个方向:高度和宽度上移动（这就是为什么这种操作被称为2D卷积，尽管3D filter用于处理3D体数据）。在每个滑动位置，我们执行逐元素乘法和加法，这导致生成单个数字。在下面所示的示例中，滑动在水平5个位置和垂直5个位置执行。总的来说，我们得到一个单一输出通道。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;../../../../images/pasted-17.png&quot; alt=&quot;考虑2D卷积的另一种方法：将该过程视为通过输入层滑动3D滤波器矩阵。请注意，输入层和filter具有相同的深度（channel数=kernel数）&quot;&gt;&lt;/p&gt;
&lt;p&gt;现在我们可以看到如何在不同深度的层之间进行过渡。假设输入层有Din通道，我们希望输出层有Dout通道。我们需要做的是将Dout filters应用于输入层。每个滤波器都有Din kernels。每个filter提供一个输出通道。应用Dout filters后，我们有Dout通道，然后可以将它们堆叠在一起形成输出层。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;../../../../images/pasted-18.png&quot; alt=&quot;标准2D卷积。使用Dout filters将具有深度Din的一个层映射到具有深度Dout的另一个层&quot;&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="深度学习" scheme="http://yoursite.com/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="卷积" scheme="http://yoursite.com/tags/%E5%8D%B7%E7%A7%AF/"/>
    
  </entry>
  
</feed>
